# Implementation Plan: Phase V — Cloud-Native AI Todo Platform

**Branch**: `002-cloud-native-platform` | **Date**: 2026-02-07 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/002-cloud-native-platform/spec.md`

## Summary

Phase V extends the existing Phase III/IV Todo AI Chatbot into an advanced,
event-driven, cloud-native platform. The implementation adds 9 advanced task
features (priority, tags, due dates, reminders, recurring tasks, search,
filter, sort), expands the AI tool-calling layer from 6 to 13 tools,
introduces Kafka-based event streaming via Dapr pub/sub, integrates all 6
Dapr building blocks, deploys to Minikube and cloud K8s (AKS), automates
CI/CD with GitHub Actions, and adds observability (Prometheus, Grafana,
OpenTelemetry) plus security guardrails.

## Technical Context

**Language/Version**: Python 3.11 (backend), TypeScript/Node 20 (frontend)
**Primary Dependencies**: FastAPI, SQLModel, OpenAI Agents SDK, Next.js 16,
Better Auth, Dapr SDK, Redpanda (Kafka-compatible)
**Storage**: Neon Serverless PostgreSQL (primary), Redis via Dapr state store
(conversation memory), Kafka/Redpanda (event streaming)
**Testing**: Manual validation + AI DevOps diagnostics (kubectl-ai, kagent)
**Target Platform**: Kubernetes (Minikube local + AKS cloud)
**Project Type**: Web application (frontend + backend + consumers)
**Performance Goals**: <2s search/filter response, <5s event producer-to-consumer,
50 concurrent users
**Constraints**: Dapr sidecar model, no direct Kafka clients in app code,
Helm-only deployments, no manual coding
**Scale/Scope**: 14 system components, 45 functional requirements, 4 user stories

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

| # | Gate | Status | Notes |
|---|------|--------|-------|
| 1 | Spec-Driven Development | PASS | All features defined in spec.md (45 FRs) |
| 2 | Zero Manual Coding | PASS | All code generated by Claude Code agents |
| 3 | Authentication-First Security | PASS | JWT on all endpoints (FR-041) |
| 4 | User Data Isolation | PASS | user_id filtering on all queries (FR-042) |
| 5 | Technology Stack Compliance | PASS | All tech from constitution stack table |
| 6 | Everything Containerized | PASS | Dockerfiles for all services (Phase 5.8) |
| 7 | Stateless by Design | PASS | State in Neon PG + Dapr state store only |
| 8 | Declarative Infrastructure | PASS | Helm charts only (Phase 5.10) |
| 9 | Event-Driven Communication | PASS | Dapr pub/sub for all async (FR-026) |
| 10 | AI MUST NOT embed CRUD logic | PASS | Tools call backend APIs only (FR-020) |
| 11 | No direct Kafka client in app | PASS | Dapr pub/sub abstraction (FR-026) |
| 12 | Helm-managed deployment | PASS | All workloads via Helm (FR-031) |
| 13 | CI/CD required | PASS | GitHub Actions pipeline (FR-036) |
| 14 | Observability required | PASS | Prometheus + Grafana + OTel (FR-038-040) |
| 15 | Secrets not in code | PASS | K8s Secrets + Dapr secret store (FR-035) |

**GATE RESULT**: ALL PASS — proceed to implementation.

## Project Structure

### Documentation (this feature)

```text
specs/002-cloud-native-platform/
├── plan.md              # This file
├── research.md          # Phase 0 research decisions
├── data-model.md        # Phase 1 entity definitions
├── quickstart.md        # Phase 1 setup guide
├── contracts/           # Phase 1 API contracts
│   ├── tasks-api.md     # Advanced task endpoints
│   ├── chat-api.md      # AI chatbot endpoints
│   ├── events-api.md    # Event schemas and topics
│   └── tools-api.md     # AI tool schemas
└── tasks.md             # Phase 2 output (/sp.tasks)
```

### Source Code (repository root)

```text
backend/
├── app/
│   ├── main.py              # FastAPI app (extend)
│   ├── models.py            # SQLModel entities (extend)
│   ├── schemas.py           # Pydantic schemas (extend)
│   ├── config.py            # Settings (extend)
│   ├── db.py                # Database engine (existing)
│   ├── dependencies.py      # JWT auth (existing)
│   ├── agent.py             # AI agent + tools (extend)
│   ├── mcp_tools.py         # Tool implementations (extend)
│   ├── events/
│   │   ├── producer.py      # Dapr pub/sub event publisher
│   │   ├── schemas.py       # Event payload schemas
│   │   └── topics.py        # Topic name constants
│   └── routes/
│       ├── tasks.py         # Task CRUD + advanced (extend)
│       ├── chat.py          # Chat endpoints (extend)
│       └── events.py        # Dapr subscription endpoints
├── Dockerfile               # Multi-stage build (update)
└── requirements.txt         # Dependencies (extend)

consumers/
├── reminder/
│   ├── main.py              # Reminder consumer service
│   ├── Dockerfile
│   └── requirements.txt
├── recurring/
│   ├── main.py              # Recurring task spawner
│   ├── Dockerfile
│   └── requirements.txt
├── audit/
│   ├── main.py              # Audit log consumer
│   ├── Dockerfile
│   └── requirements.txt
└── notification/
    ├── main.py              # Notification/sync consumer
    ├── Dockerfile
    └── requirements.txt

frontend/
├── components/
│   ├── todo/
│   │   ├── TaskCard.tsx     # Extend with priority/tags/due date
│   │   ├── TaskForm.tsx     # Extend with advanced fields
│   │   ├── TaskList.tsx     # Extend with filter/sort controls
│   │   ├── TaskFilters.tsx  # NEW: filter panel
│   │   ├── TaskSearch.tsx   # NEW: search bar
│   │   └── TaskSort.tsx     # NEW: sort dropdown
│   └── chat/                # Existing (minor updates)
├── lib/
│   └── api.ts               # Extend with advanced endpoints
├── types/
│   └── task.ts              # NEW: TypeScript interfaces
├── Dockerfile               # Existing (no change expected)
└── package.json             # Extend if needed

dapr/
├── components/
│   ├── pubsub.yaml          # Kafka/Redpanda pub/sub config
│   ├── statestore.yaml      # Redis state store config
│   ├── secretstore.yaml     # Kubernetes secret store
│   └── binding-cron.yaml    # Cron binding for recurring tasks
└── config.yaml              # Dapr configuration

helm/
├── backend/                 # Extend with Dapr annotations
├── frontend/                # Extend with Dapr annotations
├── consumers/               # NEW: consumer service charts
│   ├── reminder/
│   ├── recurring/
│   ├── audit/
│   └── notification/
├── infrastructure/          # NEW: infra charts
│   ├── redpanda/            # Kafka-compatible broker
│   ├── redis/               # Dapr state store backend
│   └── observability/       # Prometheus + Grafana
└── todo-app/                # Umbrella chart

.github/
└── workflows/
    └── ci-cd.yaml           # GitHub Actions pipeline
```

**Structure Decision**: Web application pattern with backend + frontend +
consumer microservices. Consumers are separate lightweight FastAPI services.
Infrastructure deployed via dedicated Helm charts. Dapr components stored
in `dapr/` directory and applied to cluster separately.

## Execution Phases

### Phase 5.1 — Architecture Finalization

**Objective**: Establish service boundaries, event flow, and Dapr placement.

**Key Decisions** (from research.md):
- Redpanda as Kafka broker on Minikube (R1)
- Redis as Dapr state store (R2)
- AI service embedded in backend (R4)
- 4 separate consumer services (R9)

**Service Map**:

```
Frontend ──Dapr SvcInvoke──> Backend ──Dapr PubSub──> Kafka/Redpanda
                                │                         │
                                ├── Events Producer       ├── Reminder Consumer
                                ├── AI Agent              ├── Recurring Consumer
                                └── Task CRUD             ├── Audit Consumer
                                                          └── Notification Consumer

Dapr State Store (Redis) <── Conversation Memory
Dapr Secret Store <── K8s Secrets (DB URL, API keys)
Dapr Jobs/Cron <── Reminder Scheduling
```

**Validation**: Every spec feature maps to a service; no direct cross-service
DB calls; all writes emit events via Dapr pub/sub.

---

### Phase 5.2 — Advanced Todo Features (US1: P1)

**Objective**: Extend Task model and API with priority, tags, due dates,
reminders, recurring rules, search, filter, sort.

**Steps**:
1. Extend `backend/app/models.py`: Add priority, tags, due_date,
   reminder_time, recurring_rule fields to Task. Add RecurringRule,
   Reminder, AuditLog models.
2. Extend `backend/app/schemas.py`: Add Pydantic schemas for new fields.
3. Extend `backend/app/routes/tasks.py`: Add search, filter, sort query
   parameters. Add reminder and recurring endpoints.
4. Extend `frontend/lib/api.ts`: Add advanced API methods.
5. Extend `frontend/components/todo/`: Add filter panel, search bar,
   sort dropdown, priority/tag/date UI controls.
6. Sync TypeScript types with backend schemas.

**Validation**: CRUD + all 9 advanced features working via UI and API.

---

### Phase 5.3 — AI Tooling Layer Expansion (US2: P2)

**Objective**: Define JSON schemas for all 13 tools, add validation,
permission checks, and structured result format.

**Steps**:
1. Extend `backend/app/mcp_tools.py`: Add 7 new tool functions
   (set_due_date, schedule_reminder, create_recurring, set_priority,
   add_tags, filter_tasks, sort_tasks). Update existing tools to
   support new Task fields.
2. Extend `backend/app/agent.py`: Register new tools, update system
   prompt with advanced capabilities.
3. Add tool input validation layer (JSON schema enforcement).
4. Add user ownership checks on all tool calls.
5. Add event emission on every tool call.

**Validation**: Each tool has schema, error handling, ownership check,
and emits event. AI correctly routes natural language to tools.

---

### Phase 5.4 — Event Backbone (US3: P3)

**Objective**: Define topics, event schemas, producers, and consumer
templates with idempotency.

**Steps**:
1. Create `backend/app/events/schemas.py`: Define BaseEvent, TaskEvent,
   ReminderEvent, RecurringEvent, AuditEvent, AIToolEvent.
2. Create `backend/app/events/topics.py`: Topic name constants.
3. Create `backend/app/events/producer.py`: Dapr pub/sub publisher
   using Dapr HTTP API.
4. Integrate event emission into task routes and tool implementations.
5. Create consumer service templates with idempotency key tracking.

**Topics**:
- `todo.events` — task lifecycle
- `reminder.events` — reminder scheduling
- `recurring.events` — recurring task spawning
- `ai.events` — AI tool invocations
- `audit.events` — audit trail

**Validation**: Events emitted on every write; consumers receive and
process; retry path exists with DLQ.

---

### Phase 5.5 — Dapr Runtime Integration

**Objective**: Configure all 6 Dapr building blocks.

**Steps**:
1. Create `dapr/components/pubsub.yaml`: Kafka/Redpanda pub/sub.
2. Create `dapr/components/statestore.yaml`: Redis state store.
3. Create `dapr/components/secretstore.yaml`: K8s secret store.
4. Create `dapr/components/binding-cron.yaml`: Cron binding.
5. Update backend to use Dapr HTTP API for pub/sub and state.
6. Update conversation memory to use Dapr state store.
7. Add Dapr sidecar annotations to K8s deployments.

**Validation**: Sidecars injected; service invocation works; pub/sub
delivers events; state store persists data.

---

### Phase 5.6 — Reminder & Recurring Engines

**Objective**: Implement reminder consumer and recurring task spawner.

**Steps**:
1. Create `consumers/reminder/main.py`: Subscribes to `reminder.events`,
   checks trigger_at, fires notifications via `notification.events`.
2. Create `consumers/recurring/main.py`: Subscribes to
   `recurring.events`, computes next occurrence, creates new Task via
   backend API, emits `todo.events`.
3. Integrate Dapr cron binding for periodic check of pending reminders.
4. Add duplicate prevention via idempotency keys.

**Decisions** (from research.md R3):
- Primary: Dapr Jobs API for exact-time triggers.
- Fallback: Kafka consumer with 30s polling interval.

**Validation**: Reminders fire within 60s of trigger_at; recurring tasks
spawn on schedule; duplicates prevented.

---

### Phase 5.7 — AI Chatbot Orchestration Upgrade

**Objective**: Enhance AI router for advanced tool selection, multi-turn
context, and safety guardrails.

**Steps**:
1. Update `backend/app/agent.py`: Enhanced system prompt with all 13
   tools and their capabilities.
2. Add confirmation flow for destructive operations.
3. Add prompt injection defense (input sanitization).
4. Integrate conversation memory via Dapr state store.
5. Add tool retry logic with fallback responses.
6. Update `backend/app/routes/chat.py`: Rate limiting middleware.

**Validation**: Natural language maps to correct tool; multi-turn context
maintained; destructive ops require confirmation; rate limits enforced.

---

### Phase 5.8 — Container & Image Pipeline

**Objective**: Dockerize all services with multi-stage builds.

**Steps**:
1. Update `backend/Dockerfile`: Multi-stage build, non-root user.
2. Verify `frontend/Dockerfile`: Already multi-stage (no changes expected).
3. Create `consumers/*/Dockerfile`: Lightweight Python images for each
   consumer service.
4. Create `.dockerignore` files for each service.
5. Optimize image layers and sizes.

**Validation**: All images build successfully; images are minimal;
no secrets in layers; images run locally.

---

### Phase 5.9 — Kubernetes Multi-Service Deployment

**Objective**: Deploy all workloads to Minikube with Dapr sidecars.

**Steps**:
1. Update `helm/backend/`: Add Dapr sidecar annotations, new env vars.
2. Update `helm/frontend/`: Add Dapr sidecar annotations.
3. Create `helm/consumers/*/`: Helm charts for each consumer service.
4. Create `helm/infrastructure/redpanda/`: Redpanda broker deployment.
5. Create `helm/infrastructure/redis/`: Redis for Dapr state store.
6. Apply Dapr component YAMLs to cluster.
7. Create `helm/todo-app/`: Umbrella chart for full deployment.

**Validation**: All pods Running; services reachable; Dapr sidecars
attached; end-to-end flow works.

---

### Phase 5.10 — Helm Packaging

**Objective**: Ensure all charts are production-ready with proper
parameterization.

**Steps**:
1. Parameterize all values.yaml files (image, replicas, resources,
   env, service type).
2. Add Chart.yaml metadata to all charts.
3. Run `helm lint` on all charts.
4. Test `helm install`, `helm upgrade`, `helm rollback`.
5. Create umbrella chart dependencies.

**Validation**: helm lint passes; install/upgrade/rollback work;
all config via values.yaml.

---

### Phase 5.11 — CI/CD Pipeline

**Objective**: GitHub Actions pipeline with full lifecycle.

**Steps**:
1. Create `.github/workflows/ci-cd.yaml`: Multi-job workflow.
2. Build stage: Build all Docker images.
3. Test stage: Run health checks and basic validation.
4. Scan stage: Container image vulnerability scanning.
5. Push stage: Push to GitHub Container Registry (ghcr.io).
6. Deploy stage: `helm upgrade --install` to cloud K8s (AKS).
7. Smoke test: Verify deployment health.
8. Rollback stage: `helm rollback` on failure.

**Validation**: Pipeline runs end-to-end; deploys to cluster; rollback
restores previous version.

---

### Phase 5.12 — Observability

**Objective**: Add metrics, logging, and tracing.

**Steps**:
1. Add Prometheus metrics endpoints to backend and consumers.
2. Create `helm/infrastructure/observability/`: Prometheus + Grafana
   Helm deployment.
3. Add structured JSON logging to all services.
4. Integrate OpenTelemetry SDK for distributed tracing.
5. Create Grafana dashboards for service health, event flow, AI tool
   usage.

**Validation**: Metrics collected; logs visible; tool calls traceable;
dashboards operational.

---

### Phase 5.13 — Security Hardening

**Objective**: Implement all safety guardrails.

**Steps**:
1. Add tool input validation (JSON schema enforcement).
2. Add rate limiting on chat endpoint (200 req/min per user).
3. Add prompt injection defense (pattern detection, input sanitization).
4. Add confirmation flows for delete operations in AI chatbot.
5. Add output filtering for AI responses.
6. Verify user isolation across all endpoints and tools.

**Validation**: Invalid tool calls blocked; cross-user access blocked;
secrets protected; rate limits enforced; prompt injection defended.

---

### Phase 5.14 — Failure Simulation & Validation

**Objective**: Prove system resilience.

**Steps**:
1. Kill pods and verify automatic recovery.
2. Stop Kafka broker and verify retry/DLQ behavior.
3. Test Helm rollback from broken deployment.
4. Verify AI chatbot degrades gracefully when backend is slow.
5. Verify no data loss on pod restarts.
6. Run end-to-end acceptance tests for all 4 user stories.

**Validation**: System recovers from all simulated failures; no data
loss; AI still functions; rollback works.

## Complexity Tracking

No constitution violations detected. All gates pass.

| Aspect | Complexity | Justification |
|--------|-----------|---------------|
| 4+ consumer services | Moderate | Required by constitution for independent scaling and failure isolation |
| Dapr 6 building blocks | Moderate | Required by constitution — no simpler alternative permitted |
| Multi-cloud K8s | Low | Helm charts are provider-agnostic; only values differ |
